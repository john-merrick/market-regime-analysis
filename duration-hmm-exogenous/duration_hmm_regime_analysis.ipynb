{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duration Hidden Markov Model for Market Regime Identification\n",
    "\n",
    "Implementation of the Duration HMM from **Ntantamis (2009)** — *\"A Duration Hidden Markov Model for the Identification of Regimes in Stock Market Returns\"*.\n",
    "\n",
    "**Core model:**\n",
    "- 2-state HMM (bull/bear) with mixture-of-Normals emissions ($M=3$)\n",
    "- Duration equation: $\\log \\tau = \\kappa'Z + \\zeta W$ — log-normal durations with covariates [intercept, T-bill, spread]\n",
    "- Scaled forward/backward recursions (Devijver & Dekesel 1988) for numerical stability\n",
    "- MPM state reconstruction via $\\gamma_t(i)$\n",
    "- Dietz-Böhning standard errors via deviance change\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.patches import Patch\n",
    "from scipy.stats import norm, jarque_bera\n",
    "from scipy.optimize import minimize\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({'figure.figsize': (14, 5), 'font.size': 11})\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data — S&P 500 Monthly Returns + FRED Rates\n",
    "\n",
    "We pull:\n",
    "- **S&P 500** monthly returns (via `yfinance`)\n",
    "- **3-month T-bill** secondary market rate (FRED: `TB3MS`)\n",
    "- **10-year Treasury** constant maturity rate (FRED: `GS10`)\n",
    "- **Interest rate spread** = GS10 − TB3MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr\n",
    "\n",
    "# --- S&P 500 monthly returns ---\n",
    "sp500 = yf.download('^GSPC', start='1989-12-01', end='2025-12-31', interval='1mo', auto_adjust=True)\n",
    "sp500 = sp500[['Close']].dropna()\n",
    "sp500.index = sp500.index.to_period('M').to_timestamp()\n",
    "sp500 = sp500[~sp500.index.duplicated(keep='last')]\n",
    "sp500['Return'] = sp500['Close'].pct_change()\n",
    "sp500 = sp500.dropna()\n",
    "\n",
    "# --- FRED interest rates ---\n",
    "try:\n",
    "    tbill = pdr.DataReader('TB3MS', 'fred', '1990-01-01', '2025-12-31').resample('MS').last()\n",
    "    gs10 = pdr.DataReader('GS10', 'fred', '1990-01-01', '2025-12-31').resample('MS').last()\n",
    "except Exception:\n",
    "    # Fallback: use fred directly via pandas\n",
    "    tbill = pd.read_csv(\n",
    "        'https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1168&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=TB3MS&scale=left&cosd=1990-01-01&coed=2025-12-31&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2025-01-01&revision_date=2025-01-01',\n",
    "        parse_dates=['DATE'], index_col='DATE'\n",
    "    )\n",
    "    gs10 = pd.read_csv(\n",
    "        'https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1168&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=GS10&scale=left&cosd=1990-01-01&coed=2025-12-31&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2025-01-01&revision_date=2025-01-01',\n",
    "        parse_dates=['DATE'], index_col='DATE'\n",
    "    )\n",
    "\n",
    "print(f'S&P 500 returns: {sp500.index[0].strftime(\"%Y-%m\")} to {sp500.index[-1].strftime(\"%Y-%m\")} ({len(sp500)} obs)')\n",
    "print(f'T-Bill:          {tbill.index[0].strftime(\"%Y-%m\")} to {tbill.index[-1].strftime(\"%Y-%m\")} ({len(tbill)} obs)')\n",
    "print(f'GS10:            {gs10.index[0].strftime(\"%Y-%m\")} to {gs10.index[-1].strftime(\"%Y-%m\")} ({len(gs10)} obs)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Merge and align ---\n",
    "rates = pd.DataFrame({\n",
    "    'tbill': tbill.iloc[:, 0],\n",
    "    'gs10': gs10.iloc[:, 0]\n",
    "})\n",
    "rates.index = rates.index.to_period('M').to_timestamp()\n",
    "rates = rates[~rates.index.duplicated(keep='last')]\n",
    "rates['spread'] = rates['gs10'] - rates['tbill']\n",
    "\n",
    "df = sp500[['Return']].join(rates, how='inner').dropna()\n",
    "df.columns = ['return', 'tbill', 'gs10', 'spread']\n",
    "\n",
    "# --- Train/test split (last 48 months = test) ---\n",
    "TEST_MONTHS = 48\n",
    "split_idx = len(df) - TEST_MONTHS\n",
    "df_train = df.iloc[:split_idx].copy()\n",
    "df_test = df.iloc[split_idx:].copy()\n",
    "\n",
    "print(f'Full sample:  {df.index[0].strftime(\"%Y-%m\")} to {df.index[-1].strftime(\"%Y-%m\")} ({len(df)} months)')\n",
    "print(f'Train:        {df_train.index[0].strftime(\"%Y-%m\")} to {df_train.index[-1].strftime(\"%Y-%m\")} ({len(df_train)} months)')\n",
    "print(f'Test:         {df_test.index[0].strftime(\"%Y-%m\")} to {df_test.index[-1].strftime(\"%Y-%m\")} ({len(df_test)} months)')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Descriptive statistics (in-sample / out-of-sample) ---\n",
    "def desc_stats(s, name=''):\n",
    "    return pd.Series({\n",
    "        'mean': s.mean(),\n",
    "        'std': s.std(),\n",
    "        'skewness': s.skew(),\n",
    "        'kurtosis': s.kurtosis(),\n",
    "        'min': s.min(),\n",
    "        'max': s.max(),\n",
    "        'JB stat': jarque_bera(s)[0],\n",
    "        'JB p-val': jarque_bera(s)[1],\n",
    "    }, name=name)\n",
    "\n",
    "stats_in = pd.DataFrame([desc_stats(df_train[c], c) for c in ['return', 'tbill', 'gs10', 'spread']]).T\n",
    "stats_out = pd.DataFrame([desc_stats(df_test[c], c) for c in ['return', 'tbill', 'gs10', 'spread']]).T\n",
    "\n",
    "print('=== In-Sample Descriptive Statistics ===')\n",
    "display(stats_in.round(5))\n",
    "print('\\n=== Out-of-Sample Descriptive Statistics ===')\n",
    "display(stats_out.round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Time series plots ---\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "axes[0].plot(df.index, df['return'] * 100, color='firebrick', lw=0.9)\n",
    "axes[0].axhline(0, color='k', lw=0.5)\n",
    "axes[0].axvline(df_test.index[0], color='grey', ls='--', lw=1, label='Train/Test split')\n",
    "axes[0].set_ylabel('Monthly Return (%)')\n",
    "axes[0].set_title('S&P 500 Monthly Returns')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(df.index, df['tbill'], label='3M T-Bill', color='steelblue')\n",
    "axes[1].plot(df.index, df['gs10'], label='10Y Treasury', color='darkorange')\n",
    "axes[1].axvline(df_test.index[0], color='grey', ls='--', lw=1)\n",
    "axes[1].set_ylabel('Rate (%)')\n",
    "axes[1].set_title('Interest Rates')\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].fill_between(df.index, df['spread'], alpha=0.4, color='seagreen')\n",
    "axes[2].axhline(0, color='k', lw=0.5)\n",
    "axes[2].axvline(df_test.index[0], color='grey', ls='--', lw=1)\n",
    "axes[2].set_ylabel('Spread (%)')\n",
    "axes[2].set_title('Term Spread (10Y − 3M)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Return distribution and ACF ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Histogram\n",
    "ret = df_train['return'].values\n",
    "axes[0].hist(ret, bins=50, density=True, alpha=0.6, color='steelblue', edgecolor='white')\n",
    "x_grid = np.linspace(ret.min(), ret.max(), 200)\n",
    "axes[0].plot(x_grid, norm.pdf(x_grid, ret.mean(), ret.std()), 'r-', lw=2, label='Normal fit')\n",
    "axes[0].set_title('Return Distribution (In-Sample)')\n",
    "axes[0].legend()\n",
    "\n",
    "# QQ-plot\n",
    "from scipy.stats import probplot\n",
    "probplot(ret, dist='norm', plot=axes[1])\n",
    "axes[1].set_title('Normal Q-Q Plot')\n",
    "\n",
    "# ACF\n",
    "acf_vals = acf(ret, nlags=20, fft=True)\n",
    "axes[2].bar(range(21), acf_vals, color='steelblue', width=0.6)\n",
    "axes[2].axhline(1.96/np.sqrt(len(ret)), color='r', ls='--', lw=0.8)\n",
    "axes[2].axhline(-1.96/np.sqrt(len(ret)), color='r', ls='--', lw=0.8)\n",
    "axes[2].set_title('ACF of Monthly Returns')\n",
    "axes[2].set_xlabel('Lag')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "jb_stat, jb_p = jarque_bera(ret)\n",
    "print(f'Jarque-Bera test: statistic = {jb_stat:.3f}, p-value = {jb_p:.4f}')\n",
    "print(f'  => {\"Reject\" if jb_p < 0.05 else \"Fail to reject\"} normality at 5% level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline HMM — Standard 2-State Gaussian (hmmlearn)\n",
    "\n",
    "A standard 2-state Gaussian HMM as a benchmark. This model assumes:\n",
    "- Time-homogeneous transition probabilities\n",
    "- Single Gaussian emission per state\n",
    "- No duration modelling, no exogenous covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fit standard 2-state Gaussian HMM ---\n",
    "Y_train = df_train['return'].values.reshape(-1, 1)\n",
    "\n",
    "baseline_hmm = GaussianHMM(\n",
    "    n_components=2, covariance_type='full',\n",
    "    n_iter=500, tol=1e-6, random_state=42\n",
    ")\n",
    "baseline_hmm.fit(Y_train)\n",
    "\n",
    "# Identify states: bull = higher mean\n",
    "means = baseline_hmm.means_.flatten()\n",
    "if means[0] < means[1]:\n",
    "    label_map = {0: 'Bear', 1: 'Bull'}\n",
    "else:\n",
    "    label_map = {0: 'Bull', 1: 'Bear'}\n",
    "\n",
    "print('=== Baseline HMM Results ===')\n",
    "print(f'Log-likelihood: {baseline_hmm.score(Y_train):.4f}')\n",
    "print(f'\\nInitial probs (pi): {baseline_hmm.startprob_}')\n",
    "print(f'\\nTransition matrix A:')\n",
    "print(pd.DataFrame(baseline_hmm.transmat_,\n",
    "                   index=[label_map[i] for i in range(2)],\n",
    "                   columns=[label_map[i] for i in range(2)]).round(4))\n",
    "print(f'\\nEmission parameters:')\n",
    "for i in range(2):\n",
    "    mu = baseline_hmm.means_[i, 0]\n",
    "    sigma = np.sqrt(baseline_hmm.covars_[i, 0, 0])\n",
    "    print(f'  {label_map[i]:4s}: mean = {mu:.6f}, std = {sigma:.6f}')\n",
    "    print(f'        E[duration] = {1/(1 - baseline_hmm.transmat_[i,i]):.1f} months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Baseline regime reconstruction ---\n",
    "baseline_states = baseline_hmm.predict(Y_train)\n",
    "baseline_probs = baseline_hmm.predict_proba(Y_train)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 6), sharex=True)\n",
    "\n",
    "# Determine which column is bull probability\n",
    "bull_idx = 0 if label_map[0] == 'Bull' else 1\n",
    "bull_prob = baseline_probs[:, bull_idx]\n",
    "\n",
    "axes[0].plot(df_train.index, df_train['return'] * 100, color='k', lw=0.7)\n",
    "axes[0].fill_between(df_train.index, df_train['return'].min()*100,\n",
    "                     df_train['return'].max()*100,\n",
    "                     where=bull_prob > 0.5, alpha=0.15, color='blue', label='Bull')\n",
    "axes[0].fill_between(df_train.index, df_train['return'].min()*100,\n",
    "                     df_train['return'].max()*100,\n",
    "                     where=bull_prob <= 0.5, alpha=0.15, color='orange', label='Bear')\n",
    "axes[0].set_ylabel('Return (%)')\n",
    "axes[0].set_title('Baseline HMM — Regime Classification')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(df_train.index, bull_prob, color='steelblue', lw=1)\n",
    "axes[1].axhline(0.5, color='r', ls='--', lw=0.8)\n",
    "axes[1].set_ylabel('P(Bull)')\n",
    "axes[1].set_title('Bull Market Posterior Probability')\n",
    "axes[1].set_ylim(-0.05, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Duration HMM — Full Implementation\n",
    "\n",
    "### Model specification (Ntantamis 2009)\n",
    "\n",
    "**Emissions:** Mixture of $M=3$ Normals per state $j$:\n",
    "$$b_j(y_t) = \\sum_{m=1}^{M} c_{jm} \\, f(y_t; \\mu_{jm}, \\sigma_{jm}^2)$$\n",
    "\n",
    "**Duration density:** Log-normal with covariates $Z = [1, \\text{tbill}, \\text{spread}]$:\n",
    "$$d_j(\\tau; Z) = \\frac{1}{\\tau} \\phi\\!\\left(\\frac{\\ln \\tau - \\kappa_j' Z}{\\zeta_j}\\right)$$\n",
    "\n",
    "**Transition matrix:** $A_{ii} = 0$ (no self-transitions; duration is explicit).\n",
    "\n",
    "**Forward recursion (scaled, Devijver-Dekesel):**\n",
    "$$\\alpha_t(j) = \\sum_{\\tau \\le t} \\sum_{i \\ne j} \\alpha'_{t-\\tau}(i) A_{ij} d_j(\\tau; z_{t-\\tau}) \\left[\\prod_{\\theta=1}^{\\tau-1} q_{t-\\tau+\\theta} b_j(y_{t-\\tau+\\theta})\\right] b_j(y_t)$$\n",
    "\n",
    "**Backward recursion (scaled):**\n",
    "$$\\beta_t(i) = \\sum_{\\tau \\le T-t} \\sum_{j \\ne i} A_{ij} d_j(\\tau; z_t) \\left[\\prod_{\\theta=1}^{\\tau-1} q_{t+\\theta} b_j(y_{t+\\theta})\\right] b_j(y_{t+\\tau}) \\beta'_{t+\\tau}(j)$$\n",
    "\n",
    "where $q_t = \\left[\\sum_{j=1}^n \\alpha_t(j)\\right]^{-1}$ and $\\alpha'_t(i) = \\alpha_t(i) / \\sum_j \\alpha_t(j)$, $\\beta'_t(i) = \\beta_t(i) / \\sum_j \\alpha_t(j)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DurationHMM:\n",
    "    \"\"\"\n",
    "    Duration Hidden Markov Model (Ntantamis 2009).\n",
    "    \n",
    "    - N=2 states (bull/bear)\n",
    "    - M=3 mixture-of-Normals emissions per state\n",
    "    - Log-normal duration with exogenous covariates\n",
    "    - Scaled forward/backward recursions (Devijver-Dekesel)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_states=2, n_mix=3, max_duration=None):\n",
    "        self.N = n_states\n",
    "        self.M = n_mix\n",
    "        self.max_dur = max_duration  # set during fit\n",
    "        \n",
    "        # Parameters to be estimated\n",
    "        self.pi = None       # initial state probs (N,)\n",
    "        self.A = None        # transition matrix (N, N), A_ii = 0\n",
    "        self.c = None        # mixing probs (N, M)\n",
    "        self.mu = None       # mixture means (N, M)\n",
    "        self.sigma2 = None   # mixture variances (N, M)\n",
    "        self.kappa = None    # duration regression coeffs (N, K) where K = dim(Z)\n",
    "        self.zeta = None     # duration std dev (N,)\n",
    "        \n",
    "    def _init_params(self, Y, Z):\n",
    "        \"\"\"Initialize parameters using simple heuristics.\"\"\"\n",
    "        T = len(Y)\n",
    "        K = Z.shape[1]\n",
    "        \n",
    "        # Initial state probs\n",
    "        self.pi = np.array([0.5, 0.5])\n",
    "        \n",
    "        # Transition matrix (A_ii = 0 for duration model)\n",
    "        self.A = np.array([[0.0, 1.0],\n",
    "                           [1.0, 0.0]])\n",
    "        \n",
    "        # Split data roughly in half by return magnitude for init\n",
    "        median_ret = np.median(Y)\n",
    "        high_mask = Y >= median_ret\n",
    "        low_mask = ~high_mask\n",
    "        \n",
    "        # Mixture parameters — init with K-means-like split\n",
    "        self.c = np.ones((self.N, self.M)) / self.M\n",
    "        self.mu = np.zeros((self.N, self.M))\n",
    "        self.sigma2 = np.zeros((self.N, self.M))\n",
    "        \n",
    "        for j, mask in enumerate([high_mask, low_mask]):\n",
    "            subset = Y[mask]\n",
    "            # Split subset into M roughly equal parts\n",
    "            sorted_sub = np.sort(subset)\n",
    "            chunk = max(1, len(sorted_sub) // self.M)\n",
    "            for m in range(self.M):\n",
    "                start = m * chunk\n",
    "                end = min((m+1) * chunk, len(sorted_sub))\n",
    "                if start < len(sorted_sub):\n",
    "                    self.mu[j, m] = sorted_sub[start:end].mean()\n",
    "                    self.sigma2[j, m] = max(sorted_sub[start:end].var(), 1e-6)\n",
    "                else:\n",
    "                    self.mu[j, m] = subset.mean()\n",
    "                    self.sigma2[j, m] = max(subset.var(), 1e-6)\n",
    "        \n",
    "        # Duration parameters\n",
    "        self.kappa = np.zeros((self.N, K))\n",
    "        self.kappa[:, 0] = np.log(12)  # intercept => ~12 months expected duration\n",
    "        self.zeta = np.ones(self.N) * 1.0\n",
    "    \n",
    "    def _emission_prob(self, y, j):\n",
    "        \"\"\"Mixture-of-normals emission probability b_j(y).\"\"\"\n",
    "        prob = 0.0\n",
    "        for m in range(self.M):\n",
    "            prob += self.c[j, m] * norm.pdf(y, self.mu[j, m], np.sqrt(self.sigma2[j, m]))\n",
    "        return max(prob, 1e-300)\n",
    "    \n",
    "    def _emission_prob_all(self, Y):\n",
    "        \"\"\"Compute b_j(y_t) for all t, j. Returns (T, N) array.\"\"\"\n",
    "        T = len(Y)\n",
    "        B = np.zeros((T, self.N))\n",
    "        for j in range(self.N):\n",
    "            for m in range(self.M):\n",
    "                B[:, j] += self.c[j, m] * norm.pdf(Y, self.mu[j, m], np.sqrt(self.sigma2[j, m]))\n",
    "        B = np.maximum(B, 1e-300)\n",
    "        return B\n",
    "    \n",
    "    def _duration_prob(self, tau, z, j):\n",
    "        \"\"\"Log-normal duration density d_j(tau; Z). Eq (7).\"\"\"\n",
    "        if tau < 1:\n",
    "            return 0.0\n",
    "        log_tau = np.log(tau)\n",
    "        mean = self.kappa[j] @ z\n",
    "        std = self.zeta[j]\n",
    "        return (1.0 / tau) * norm.pdf((log_tau - mean) / std) / std\n",
    "    \n",
    "    def _duration_prob_matrix(self, Z, max_dur):\n",
    "        \"\"\"\n",
    "        Precompute d_j(tau; z_t) for all t, j, tau.\n",
    "        Returns (T, N, max_dur) where index [t, j, d] = d_j(d+1; z_t).\n",
    "        \"\"\"\n",
    "        T = Z.shape[0]\n",
    "        D = np.zeros((T, self.N, max_dur))\n",
    "        taus = np.arange(1, max_dur + 1, dtype=float)\n",
    "        log_taus = np.log(taus)\n",
    "        \n",
    "        for j in range(self.N):\n",
    "            for t in range(T):\n",
    "                mean = self.kappa[j] @ Z[t]\n",
    "                std = self.zeta[j]\n",
    "                D[t, j, :] = (1.0 / taus) * norm.pdf((log_taus - mean) / std) / std\n",
    "        \n",
    "        return D\n",
    "    \n",
    "    def _forward_backward(self, Y, Z, B, D, max_dur):\n",
    "        \"\"\"\n",
    "        Scaled forward-backward recursions (Devijver-Dekesel).\n",
    "        Eqs (28)-(33) from the paper.\n",
    "        \n",
    "        Returns:\n",
    "            alpha_prime: (T, N) scaled forward probs\n",
    "            beta_prime: (T, N) scaled backward probs  \n",
    "            q: (T,) scaling factors\n",
    "            log_lik: total log-likelihood\n",
    "        \"\"\"\n",
    "        T = len(Y)\n",
    "        N = self.N\n",
    "        \n",
    "        alpha = np.zeros((T, N))       # unscaled forward\n",
    "        alpha_prime = np.zeros((T, N)) # scaled forward = alpha / sum(alpha)\n",
    "        q = np.zeros(T)                # q_t = 1 / sum_j alpha_t(j)\n",
    "        log_lik = 0.0\n",
    "        \n",
    "        # --- Forward pass ---\n",
    "        # t=0: alpha_1(j) = pi_j * b_j(y_1) * d_j(1; z_1)\n",
    "        for j in range(N):\n",
    "            alpha[0, j] = self.pi[j] * B[0, j] * D[0, j, 0]\n",
    "        \n",
    "        s = alpha[0].sum()\n",
    "        if s > 0:\n",
    "            q[0] = 1.0 / s\n",
    "            alpha_prime[0] = alpha[0] / s\n",
    "            log_lik += np.log(s)\n",
    "        else:\n",
    "            q[0] = 1.0\n",
    "            alpha_prime[0] = 1.0 / N\n",
    "        \n",
    "        # t=1..T-1\n",
    "        for t in range(1, T):\n",
    "            for j in range(N):\n",
    "                val = 0.0\n",
    "                # Sum over durations tau=1..min(t+1, max_dur)\n",
    "                max_tau = min(t + 1, max_dur)\n",
    "                for tau in range(1, max_tau + 1):\n",
    "                    t_start = t - tau  # time of transition\n",
    "                    \n",
    "                    # Product of scaled emission probs within the duration\n",
    "                    # For theta=1..tau-1: q_{t-tau+theta} * b_j(y_{t-tau+theta})\n",
    "                    # Plus the final b_j(y_t)\n",
    "                    prod_b = B[t, j]  # the final emission\n",
    "                    for theta in range(1, tau):\n",
    "                        idx = t_start + theta\n",
    "                        prod_b *= q[idx] * B[idx, j]\n",
    "                    \n",
    "                    # Duration prob at the start time\n",
    "                    dur_p = D[max(t_start, 0), j, tau - 1]\n",
    "                    \n",
    "                    if t_start < 0:\n",
    "                        # Comes from initial state\n",
    "                        val += self.pi[j] * dur_p * prod_b\n",
    "                    else:\n",
    "                        # Comes from transition\n",
    "                        for i in range(N):\n",
    "                            if i != j:\n",
    "                                val += alpha_prime[t_start, i] * self.A[i, j] * dur_p * prod_b\n",
    "                \n",
    "                alpha[t, j] = val\n",
    "            \n",
    "            s = alpha[t].sum()\n",
    "            if s > 0:\n",
    "                q[t] = 1.0 / s\n",
    "                alpha_prime[t] = alpha[t] / s\n",
    "                log_lik += np.log(s)\n",
    "            else:\n",
    "                q[t] = q[t-1]\n",
    "                alpha_prime[t] = alpha_prime[t-1]\n",
    "        \n",
    "        # --- Backward pass ---\n",
    "        beta = np.zeros((T, N))\n",
    "        beta_prime = np.zeros((T, N))\n",
    "        \n",
    "        # t=T-1: beta_T(j) = 1\n",
    "        beta[T-1] = 1.0\n",
    "        s_alpha = alpha[T-1].sum()\n",
    "        if s_alpha > 0:\n",
    "            beta_prime[T-1] = beta[T-1] / s_alpha\n",
    "        else:\n",
    "            beta_prime[T-1] = 1.0 / N\n",
    "        \n",
    "        for t in range(T-2, -1, -1):\n",
    "            for i in range(N):\n",
    "                val = 0.0\n",
    "                max_tau = min(T - t, max_dur)\n",
    "                for tau in range(1, max_tau):\n",
    "                    t_end = t + tau\n",
    "                    for j_next in range(N):\n",
    "                        if j_next != i:\n",
    "                            dur_p = D[t, j_next, tau - 1]\n",
    "                            \n",
    "                            prod_b = B[t_end, j_next]  # b_j(y_{t+tau})\n",
    "                            for theta in range(1, tau):\n",
    "                                idx = t + theta\n",
    "                                prod_b *= q[idx] * B[idx, j_next]\n",
    "                            \n",
    "                            val += self.A[i, j_next] * dur_p * prod_b * beta_prime[t_end, j_next]\n",
    "                \n",
    "                beta[t, i] = val\n",
    "            \n",
    "            s_alpha = alpha[t].sum()\n",
    "            if s_alpha > 0:\n",
    "                beta_prime[t] = beta[t] / s_alpha\n",
    "            else:\n",
    "                beta_prime[t] = beta_prime[t+1]\n",
    "        \n",
    "        return alpha_prime, beta_prime, q, log_lik\n",
    "    \n",
    "    def _compute_gamma(self, alpha_prime, beta_prime, q):\n",
    "        \"\"\"Compute gamma_t(i) = P(X_t = i | Y_{1:T}). Eq (13).\"\"\"\n",
    "        T = alpha_prime.shape[0]\n",
    "        gamma = alpha_prime * beta_prime / q[:, None]\n",
    "        # Normalize\n",
    "        row_sums = gamma.sum(axis=1, keepdims=True)\n",
    "        row_sums = np.where(row_sums > 0, row_sums, 1.0)\n",
    "        gamma = gamma / row_sums\n",
    "        return gamma\n",
    "    \n",
    "    def _m_step_emissions(self, Y, gamma):\n",
    "        \"\"\"Update mixture emission parameters (c, mu, sigma2). Eqs (17)-(19).\"\"\"\n",
    "        T = len(Y)\n",
    "        \n",
    "        for j in range(self.N):\n",
    "            # Compute mixture responsibilities w_{jm}(t)\n",
    "            w = np.zeros((T, self.M))\n",
    "            for m in range(self.M):\n",
    "                w[:, m] = self.c[j, m] * norm.pdf(Y, self.mu[j, m], np.sqrt(self.sigma2[j, m]))\n",
    "            w_sum = w.sum(axis=1, keepdims=True)\n",
    "            w_sum = np.where(w_sum > 0, w_sum, 1.0)\n",
    "            w = w / w_sum\n",
    "            \n",
    "            # gamma_t(j, k) = gamma_t(j) * w_{jk}(t)\n",
    "            gamma_jk = gamma[:, j:j+1] * w  # (T, M)\n",
    "            \n",
    "            # Update mixing probs\n",
    "            gamma_jk_sum = gamma_jk.sum(axis=0)\n",
    "            total = gamma_jk_sum.sum()\n",
    "            if total > 0:\n",
    "                self.c[j] = gamma_jk_sum / total\n",
    "            \n",
    "            # Update means and variances\n",
    "            for m in range(self.M):\n",
    "                denom = gamma_jk[:, m].sum()\n",
    "                if denom > 1e-10:\n",
    "                    self.mu[j, m] = (gamma_jk[:, m] * Y).sum() / denom\n",
    "                    self.sigma2[j, m] = max(\n",
    "                        (gamma_jk[:, m] * (Y - self.mu[j, m])**2).sum() / denom,\n",
    "                        1e-8\n",
    "                    )\n",
    "    \n",
    "    def _m_step_transition(self, alpha_prime, beta_prime, q, B, D, Z, max_dur):\n",
    "        \"\"\"Update transition matrix A. Eq (33).\"\"\"\n",
    "        T = len(alpha_prime)\n",
    "        num = np.zeros((self.N, self.N))\n",
    "        denom = np.zeros(self.N)\n",
    "        \n",
    "        for t in range(T-1):\n",
    "            for i in range(self.N):\n",
    "                denom[i] += alpha_prime[t, i] * beta_prime[t, i] / q[t]\n",
    "                for j in range(self.N):\n",
    "                    if i != j:\n",
    "                        # Sum over valid durations\n",
    "                        max_tau = min(T - t, max_dur)\n",
    "                        for tau in range(1, max_tau):\n",
    "                            t_end = t + tau\n",
    "                            dur_p = D[t, j, tau - 1]\n",
    "                            \n",
    "                            prod_b = B[t_end, j]\n",
    "                            for theta in range(1, tau):\n",
    "                                prod_b *= q[t + theta] * B[t + theta, j]\n",
    "                            \n",
    "                            num[i, j] += alpha_prime[t, i] * self.A[i, j] * dur_p * prod_b * beta_prime[t_end, j]\n",
    "        \n",
    "        # Update A (keep A_ii = 0)\n",
    "        for i in range(self.N):\n",
    "            for j in range(self.N):\n",
    "                if i != j and denom[i] > 1e-10:\n",
    "                    self.A[i, j] = num[i, j] / denom[i]\n",
    "            # Normalize row (excluding diagonal)\n",
    "            row_sum = sum(self.A[i, k] for k in range(self.N) if k != i)\n",
    "            if row_sum > 0:\n",
    "                for j in range(self.N):\n",
    "                    if i != j:\n",
    "                        self.A[i, j] /= row_sum\n",
    "    \n",
    "    def _m_step_duration(self, Y, Z, alpha_prime, beta_prime, q, B, D, max_dur):\n",
    "        \"\"\"\n",
    "        MLE for duration parameters (kappa, zeta) via numerical optimization.\n",
    "        Uses the gradient conditions from Eqs (22)-(25).\n",
    "        \"\"\"\n",
    "        T = len(Y)\n",
    "        K = Z.shape[1]\n",
    "        \n",
    "        for j in range(self.N):\n",
    "            def neg_dur_loglik(params):\n",
    "                kap = params[:K]\n",
    "                zet = max(params[K], 0.01)\n",
    "                \n",
    "                ll = 0.0\n",
    "                for t in range(T-1):\n",
    "                    max_tau = min(T - t, max_dur)\n",
    "                    for tau in range(1, max_tau):\n",
    "                        log_tau = np.log(tau)\n",
    "                        mean = kap @ Z[t]\n",
    "                        d_val = (1.0/tau) * norm.pdf((log_tau - mean)/zet) / zet\n",
    "                        \n",
    "                        if d_val > 1e-300:\n",
    "                            # Weight by forward-backward\n",
    "                            t_end = t + tau\n",
    "                            if t_end < T:\n",
    "                                for i in range(self.N):\n",
    "                                    if i != j:\n",
    "                                        prod_b = B[t_end, j]\n",
    "                                        for theta in range(1, tau):\n",
    "                                            prod_b *= q[t+theta] * B[t+theta, j]\n",
    "                                        \n",
    "                                        weight = alpha_prime[t, i] * self.A[i, j] * prod_b * beta_prime[t_end, j]\n",
    "                                        if weight > 0 and d_val > 0:\n",
    "                                            ll += weight * np.log(max(d_val, 1e-300))\n",
    "                \n",
    "                return -ll\n",
    "            \n",
    "            x0 = np.concatenate([self.kappa[j], [self.zeta[j]]])\n",
    "            bounds = [(None, None)] * K + [(0.01, 5.0)]\n",
    "            \n",
    "            try:\n",
    "                res = minimize(neg_dur_loglik, x0, method='L-BFGS-B',\n",
    "                             bounds=bounds, options={'maxiter': 50, 'ftol': 1e-6})\n",
    "                if res.success or res.fun < neg_dur_loglik(x0):\n",
    "                    self.kappa[j] = res.x[:K]\n",
    "                    self.zeta[j] = max(res.x[K], 0.01)\n",
    "            except Exception:\n",
    "                pass\n",
    "    \n",
    "    def fit(self, Y, Z, max_iter=30, tol=1e-4, max_duration=None, verbose=True):\n",
    "        \"\"\"\n",
    "        Fit Duration HMM via EM.\n",
    "        \n",
    "        Parameters:\n",
    "            Y: (T,) observation sequence (returns)\n",
    "            Z: (T, K) exogenous covariates (should include intercept column)\n",
    "            max_iter: maximum EM iterations\n",
    "            tol: convergence tolerance on log-likelihood\n",
    "            max_duration: cap on duration (for computational tractability)\n",
    "        \"\"\"\n",
    "        T = len(Y)\n",
    "        if max_duration is None:\n",
    "            max_duration = min(T // 3, 60)  # cap at 60 months or T/3\n",
    "        self.max_dur = max_duration\n",
    "        \n",
    "        self._init_params(Y, Z)\n",
    "        \n",
    "        log_liks = []\n",
    "        \n",
    "        for iteration in range(max_iter):\n",
    "            # --- E step ---\n",
    "            B = self._emission_prob_all(Y)\n",
    "            D = self._duration_prob_matrix(Z, self.max_dur)\n",
    "            alpha_prime, beta_prime, q, log_lik = self._forward_backward(Y, Z, B, D, self.max_dur)\n",
    "            gamma = self._compute_gamma(alpha_prime, beta_prime, q)\n",
    "            \n",
    "            log_liks.append(log_lik)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f'  Iter {iteration+1:3d}: log-lik = {log_lik:.4f}')\n",
    "            \n",
    "            # Check convergence\n",
    "            if iteration > 0 and abs(log_liks[-1] - log_liks[-2]) < tol:\n",
    "                if verbose:\n",
    "                    print(f'  Converged at iteration {iteration+1}')\n",
    "                break\n",
    "            \n",
    "            # --- M step ---\n",
    "            # Update initial probs\n",
    "            self.pi = gamma[0]\n",
    "            self.pi = np.maximum(self.pi, 1e-6)\n",
    "            self.pi /= self.pi.sum()\n",
    "            \n",
    "            # Update emissions\n",
    "            self._m_step_emissions(Y, gamma)\n",
    "            \n",
    "            # Update transition matrix\n",
    "            self._m_step_transition(alpha_prime, beta_prime, q, B, D, Z, self.max_dur)\n",
    "            \n",
    "            # Update duration parameters\n",
    "            self._m_step_duration(Y, Z, alpha_prime, beta_prime, q, B, D, self.max_dur)\n",
    "        \n",
    "        # Final E-step for gamma\n",
    "        B = self._emission_prob_all(Y)\n",
    "        D = self._duration_prob_matrix(Z, self.max_dur)\n",
    "        alpha_prime, beta_prime, q, log_lik = self._forward_backward(Y, Z, B, D, self.max_dur)\n",
    "        self.gamma_ = self._compute_gamma(alpha_prime, beta_prime, q)\n",
    "        self.log_liks_ = log_liks\n",
    "        self.log_lik_ = log_lik\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def mpm_states(self):\n",
    "        \"\"\"Maximum Posterior Mode state sequence. Eq (41).\"\"\"\n",
    "        return np.argmax(self.gamma_, axis=1)\n",
    "    \n",
    "    def viterbi(self, Y, Z):\n",
    "        \"\"\"Viterbi decoding for MAP state sequence.\"\"\"\n",
    "        T = len(Y)\n",
    "        B = self._emission_prob_all(Y)\n",
    "        D = self._duration_prob_matrix(Z, self.max_dur)\n",
    "        \n",
    "        # log-space Viterbi\n",
    "        log_delta = np.full((T, self.N), -np.inf)\n",
    "        psi = np.zeros((T, self.N), dtype=int)\n",
    "        \n",
    "        for j in range(self.N):\n",
    "            if self.pi[j] > 0 and B[0, j] > 0 and D[0, j, 0] > 0:\n",
    "                log_delta[0, j] = np.log(self.pi[j]) + np.log(B[0, j]) + np.log(D[0, j, 0])\n",
    "        \n",
    "        for t in range(1, T):\n",
    "            for j in range(self.N):\n",
    "                best_val = -np.inf\n",
    "                best_i = 0\n",
    "                max_tau = min(t + 1, self.max_dur)\n",
    "                \n",
    "                for tau in range(1, max_tau + 1):\n",
    "                    t_start = t - tau\n",
    "                    log_b_prod = np.log(max(B[t, j], 1e-300))\n",
    "                    for theta in range(1, tau):\n",
    "                        log_b_prod += np.log(max(B[t_start + theta, j], 1e-300))\n",
    "                    \n",
    "                    dur_p = D[max(t_start, 0), j, tau - 1]\n",
    "                    log_dur = np.log(max(dur_p, 1e-300))\n",
    "                    \n",
    "                    if t_start < 0:\n",
    "                        val = np.log(max(self.pi[j], 1e-300)) + log_dur + log_b_prod\n",
    "                        if val > best_val:\n",
    "                            best_val = val\n",
    "                            best_i = j\n",
    "                    else:\n",
    "                        for i in range(self.N):\n",
    "                            if i != j and self.A[i, j] > 0:\n",
    "                                val = log_delta[t_start, i] + np.log(self.A[i, j]) + log_dur + log_b_prod\n",
    "                                if val > best_val:\n",
    "                                    best_val = val\n",
    "                                    best_i = i\n",
    "                \n",
    "                log_delta[t, j] = best_val\n",
    "                psi[t, j] = best_i\n",
    "        \n",
    "        # Backtrack\n",
    "        states = np.zeros(T, dtype=int)\n",
    "        states[T-1] = np.argmax(log_delta[T-1])\n",
    "        for t in range(T-2, -1, -1):\n",
    "            states[t] = psi[t+1, states[t+1]]\n",
    "        \n",
    "        return states\n",
    "    \n",
    "    def expected_duration(self, z, j):\n",
    "        \"\"\"Expected duration for state j given covariates z. Eq (39): E(tau) = exp(kappa'Z + zeta^2/2).\"\"\"\n",
    "        return np.exp(self.kappa[j] @ z + self.zeta[j]**2 / 2)\n",
    "    \n",
    "    def forecast_paths(self, Z_future, n_paths=5000):\n",
    "        \"\"\"\n",
    "        Simulate forecast paths per Section 2.5.\n",
    "        \n",
    "        Parameters:\n",
    "            Z_future: (H, K) future covariates for H periods ahead\n",
    "            n_paths: number of Monte Carlo paths\n",
    "        \n",
    "        Returns:\n",
    "            paths: (n_paths, H) simulated returns\n",
    "        \"\"\"\n",
    "        H = Z_future.shape[0]\n",
    "        paths = np.zeros((n_paths, H))\n",
    "        \n",
    "        for v in range(n_paths):\n",
    "            t = 0\n",
    "            # Draw initial state\n",
    "            state = np.random.choice(self.N, p=self.pi)\n",
    "            \n",
    "            while t < H:\n",
    "                # Draw duration from log-normal\n",
    "                mean = self.kappa[state] @ Z_future[min(t, H-1)]\n",
    "                log_dur = mean + self.zeta[state] * np.random.randn()\n",
    "                dur = max(1, int(np.round(np.exp(log_dur))))\n",
    "                \n",
    "                # Fill returns for this duration\n",
    "                # Draw from mixture for this state\n",
    "                for d in range(dur):\n",
    "                    if t + d >= H:\n",
    "                        break\n",
    "                    # Pick mixture component\n",
    "                    comp = np.random.choice(self.M, p=self.c[state])\n",
    "                    paths[v, t + d] = np.random.normal(self.mu[state, comp],\n",
    "                                                       np.sqrt(self.sigma2[state, comp]))\n",
    "                \n",
    "                t += dur\n",
    "                \n",
    "                # Transition to next state (A_ii = 0)\n",
    "                probs = self.A[state].copy()\n",
    "                probs[state] = 0\n",
    "                if probs.sum() > 0:\n",
    "                    probs /= probs.sum()\n",
    "                    state = np.random.choice(self.N, p=probs)\n",
    "                else:\n",
    "                    state = 1 - state  # 2-state: just flip\n",
    "        \n",
    "        return paths\n",
    "    \n",
    "    def standard_errors_deviance(self, Y, Z):\n",
    "        \"\"\"\n",
    "        Dietz-Böhning standard errors via deviance change. Eq (34).\n",
    "        s.e.(lambda_i) = |lambda_i| / sqrt(2 * (l_full - l_restricted))\n",
    "        \"\"\"\n",
    "        B = self._emission_prob_all(Y)\n",
    "        D = self._duration_prob_matrix(Z, self.max_dur)\n",
    "        _, _, _, ll_full = self._forward_backward(Y, Z, B, D, self.max_dur)\n",
    "        \n",
    "        se_dict = {}\n",
    "        \n",
    "        # Standard errors for duration parameters\n",
    "        for j in range(self.N):\n",
    "            K = Z.shape[1]\n",
    "            for k in range(K):\n",
    "                orig_val = self.kappa[j, k]\n",
    "                self.kappa[j, k] = 0.0\n",
    "                \n",
    "                D_r = self._duration_prob_matrix(Z, self.max_dur)\n",
    "                _, _, _, ll_r = self._forward_backward(Y, Z, B, D_r, self.max_dur)\n",
    "                \n",
    "                self.kappa[j, k] = orig_val\n",
    "                \n",
    "                dev_change = 2 * (ll_full - ll_r)\n",
    "                if dev_change > 0:\n",
    "                    se_dict[f'kappa_{j+1},{k+1}'] = abs(orig_val) / np.sqrt(dev_change)\n",
    "                else:\n",
    "                    se_dict[f'kappa_{j+1},{k+1}'] = np.nan\n",
    "        \n",
    "        return se_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare data ---\n",
    "Y_tr = df_train['return'].values\n",
    "Z_tr = np.column_stack([\n",
    "    np.ones(len(df_train)),       # intercept\n",
    "    df_train['tbill'].values,     # T-bill rate\n",
    "    df_train['spread'].values     # interest rate spread\n",
    "])\n",
    "\n",
    "print(f'Training: T={len(Y_tr)}, K={Z_tr.shape[1]} covariates [intercept, tbill, spread]')\n",
    "print(f'Max duration capped at {min(len(Y_tr)//3, 60)} months\\n')\n",
    "\n",
    "# --- Fit Duration HMM ---\n",
    "dhmm = DurationHMM(n_states=2, n_mix=3)\n",
    "dhmm.fit(Y_tr, Z_tr, max_iter=30, tol=1e-4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EM convergence ---\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(range(1, len(dhmm.log_liks_)+1), dhmm.log_liks_, 'o-', color='steelblue')\n",
    "ax.set_xlabel('EM Iteration')\n",
    "ax.set_ylabel('Log-Likelihood')\n",
    "ax.set_title('Duration HMM — EM Convergence')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameter tables ---\n",
    "\n",
    "# Identify bull/bear: bull = higher mean return (weighted by mixture)\n",
    "state_means = [(dhmm.c[j] * dhmm.mu[j]).sum() for j in range(2)]\n",
    "state_vars = [(dhmm.c[j] * (dhmm.sigma2[j] + dhmm.mu[j]**2)).sum() - state_means[j]**2 for j in range(2)]\n",
    "bull_state = int(np.argmax(state_means))\n",
    "bear_state = 1 - bull_state\n",
    "state_labels = {bull_state: 'Bull (State 1)', bear_state: 'Bear (State 2)'}\n",
    "\n",
    "print('=== Markov Chain Parameters ===')\n",
    "print(f'Initial probs (pi): Bull={dhmm.pi[bull_state]:.4f}, Bear={dhmm.pi[bear_state]:.4f}')\n",
    "print(f'\\nTransition matrix A (A_ii = 0 by construction):')\n",
    "A_df = pd.DataFrame(dhmm.A, \n",
    "                    index=[state_labels[i] for i in range(2)],\n",
    "                    columns=[state_labels[i] for i in range(2)])\n",
    "display(A_df.round(4))\n",
    "\n",
    "print('\\n=== Mixture-of-Normals Emission Parameters ===')\n",
    "for j in range(2):\n",
    "    print(f'\\n  {state_labels[j]}:')\n",
    "    em_df = pd.DataFrame({\n",
    "        'Mixing Prob': dhmm.c[j],\n",
    "        'Mean': dhmm.mu[j],\n",
    "        'Variance': dhmm.sigma2[j],\n",
    "        'Std Dev': np.sqrt(dhmm.sigma2[j])\n",
    "    }, index=[f'Component {m+1}' for m in range(dhmm.M)])\n",
    "    display(em_df.round(6))\n",
    "\n",
    "print(f'\\n  Overall state characteristics:')\n",
    "char_df = pd.DataFrame({\n",
    "    'Mean': state_means,\n",
    "    'Variance': state_vars,\n",
    "    'Variability Coef': [np.sqrt(v)/abs(m) if abs(m) > 1e-8 else np.nan for m, v in zip(state_means, state_vars)]\n",
    "}, index=[state_labels[i] for i in range(2)])\n",
    "display(char_df.round(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Duration parameter table ---\n",
    "print('=== Duration Model Parameters ===')\n",
    "print('log(tau) = kappa_1 + kappa_2 * tbill + kappa_3 * spread + zeta * W\\n')\n",
    "\n",
    "# Compute standard errors\n",
    "se = dhmm.standard_errors_deviance(Y_tr, Z_tr)\n",
    "\n",
    "dur_rows = []\n",
    "param_names = ['kappa_1 (intercept)', 'kappa_2 (T-bill)', 'kappa_3 (spread)', 'zeta']\n",
    "for j in range(2):\n",
    "    row = {}\n",
    "    for k in range(3):\n",
    "        row[f'Coeff'] = None  # placeholder\n",
    "    dur_rows.append(row)\n",
    "\n",
    "for j in range(2):\n",
    "    print(f'  {state_labels[j]}:')\n",
    "    data = []\n",
    "    for k in range(3):\n",
    "        se_key = f'kappa_{j+1},{k+1}'\n",
    "        se_val = se.get(se_key, np.nan)\n",
    "        data.append({\n",
    "            'Parameter': param_names[k],\n",
    "            'Coefficient': dhmm.kappa[j, k],\n",
    "            'Std. Error': se_val\n",
    "        })\n",
    "    data.append({\n",
    "        'Parameter': param_names[3],\n",
    "        'Coefficient': dhmm.zeta[j],\n",
    "        'Std. Error': np.nan\n",
    "    })\n",
    "    display(pd.DataFrame(data).set_index('Parameter').round(4))\n",
    "\n",
    "# Expected durations at sample mean covariates\n",
    "z_mean = Z_tr.mean(axis=0)\n",
    "print(f'\\nExpected durations at sample-mean covariates (tbill={z_mean[1]:.2f}%, spread={z_mean[2]:.2f}%):')\n",
    "for j in range(2):\n",
    "    ed = dhmm.expected_duration(z_mean, j)\n",
    "    print(f'  {state_labels[j]}: E[tau] = {ed:.1f} months')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quantitative Analysis — Duration Elasticities & Policy Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Duration elasticities ---\n",
    "# E(tau) = exp(kappa'Z + zeta^2/2)\n",
    "# d E(tau) / d Z_k = kappa_k * E(tau)\n",
    "# % change in E(tau) for 1% change in Z_k = kappa_k (semi-elasticity)\n",
    "# For 1 ppt increase in rate: % change = exp(kappa_k * 1) - 1\n",
    "\n",
    "print('=== Duration Elasticities ===')\n",
    "print('Effect of 1 percentage point increase in each covariate on expected duration:\\n')\n",
    "\n",
    "z_base = Z_tr.mean(axis=0)\n",
    "\n",
    "for j in range(2):\n",
    "    ed_base = dhmm.expected_duration(z_base, j)\n",
    "    print(f'{state_labels[j]} (baseline E[tau] = {ed_base:.1f} months):')\n",
    "    \n",
    "    # T-bill +1%\n",
    "    z_tbill = z_base.copy()\n",
    "    z_tbill[1] += 1.0\n",
    "    ed_tbill = dhmm.expected_duration(z_tbill, j)\n",
    "    pct_tbill = (ed_tbill / ed_base - 1) * 100\n",
    "    print(f'  T-bill +1%:   E[tau] = {ed_tbill:.1f} months ({pct_tbill:+.1f}%)')\n",
    "    \n",
    "    # Spread +1%\n",
    "    z_spread = z_base.copy()\n",
    "    z_spread[2] += 1.0\n",
    "    ed_spread = dhmm.expected_duration(z_spread, j)\n",
    "    pct_spread = (ed_spread / ed_base - 1) * 100\n",
    "    print(f'  Spread +1%:   E[tau] = {ed_spread:.1f} months ({pct_spread:+.1f}%)')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Policy scenarios: +/-25bp Fed rate change ---\n",
    "# Assumption: 25bp cut in Fed rate => T-bill drops ~25bp, spread increases ~11bp\n",
    "# (based on typical pass-through; Ntantamis uses full and partial pass-through)\n",
    "\n",
    "print('=== Policy Scenarios: Fed Rate Changes ===')\n",
    "print('Assumption: 25bp Fed cut => T-bill -25bp, spread +11bp\\n')\n",
    "\n",
    "scenarios = [\n",
    "    ('Fed -25bp (easing)', -0.25, +0.11),\n",
    "    ('Fed +25bp (tightening)', +0.25, -0.11),\n",
    "    ('Fed -50bp (aggressive easing)', -0.50, +0.22),\n",
    "    ('Fed +50bp (aggressive tightening)', +0.50, -0.22),\n",
    "]\n",
    "\n",
    "z_now = Z_tr[-1].copy()  # latest covariates\n",
    "print(f'Current rates: T-bill = {z_now[1]:.2f}%, spread = {z_now[2]:.2f}%\\n')\n",
    "\n",
    "results = []\n",
    "for name, d_tbill, d_spread in scenarios:\n",
    "    row = {'Scenario': name}\n",
    "    z_scen = z_now.copy()\n",
    "    z_scen[1] += d_tbill\n",
    "    z_scen[2] += d_spread\n",
    "    \n",
    "    for j in range(2):\n",
    "        ed_base = dhmm.expected_duration(z_now, j)\n",
    "        ed_scen = dhmm.expected_duration(z_scen, j)\n",
    "        pct = (ed_scen / ed_base - 1) * 100\n",
    "        row[f'{state_labels[j]} E[tau]'] = f'{ed_scen:.1f}m ({pct:+.1f}%)'\n",
    "    results.append(row)\n",
    "\n",
    "display(pd.DataFrame(results).set_index('Scenario'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Rate sensitivity surface ---\n",
    "tbill_grid = np.linspace(0, 8, 50)\n",
    "spread_grid = np.linspace(-1, 4, 50)\n",
    "TB, SP = np.meshgrid(tbill_grid, spread_grid)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for idx, j in enumerate([bull_state, bear_state]):\n",
    "    ED = np.zeros_like(TB)\n",
    "    for ii in range(50):\n",
    "        for jj in range(50):\n",
    "            z = np.array([1.0, TB[ii, jj], SP[ii, jj]])\n",
    "            ED[ii, jj] = dhmm.expected_duration(z, j)\n",
    "    \n",
    "    # Clip for visualization\n",
    "    ED = np.clip(ED, 0, 120)\n",
    "    \n",
    "    cs = axes[idx].contourf(TB, SP, ED, levels=20, cmap='RdYlGn' if j == bull_state else 'RdYlGn_r')\n",
    "    axes[idx].set_xlabel('T-Bill Rate (%)')\n",
    "    axes[idx].set_ylabel('Spread (%)')\n",
    "    axes[idx].set_title(f'{state_labels[j]} — Expected Duration (months)')\n",
    "    plt.colorbar(cs, ax=axes[idx])\n",
    "    \n",
    "    # Mark current position\n",
    "    axes[idx].plot(z_now[1], z_now[2], 'k*', markersize=15, label='Current')\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Regime Reconstruction — MPM + Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MPM state reconstruction ---\n",
    "mpm_states = dhmm.mpm_states()\n",
    "bull_prob_dhmm = dhmm.gamma_[:, bull_state]\n",
    "\n",
    "# --- Viterbi ---\n",
    "viterbi_states = dhmm.viterbi(Y_tr, Z_tr)\n",
    "\n",
    "# --- Known crisis events for annotation ---\n",
    "crises = [\n",
    "    ('1990-07', '1991-03', 'Gulf War\\nRecession'),\n",
    "    ('1997-07', '1998-10', 'Asian/LTCM\\nCrisis'),\n",
    "    ('2000-03', '2002-10', 'Dot-com\\nBust'),\n",
    "    ('2007-12', '2009-06', 'GFC'),\n",
    "    ('2020-02', '2020-04', 'COVID'),\n",
    "    ('2022-01', '2022-10', 'Rate Hike\\nSelloff'),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 10), sharex=True)\n",
    "\n",
    "# Panel 1: Returns with regime shading (MPM)\n",
    "ax = axes[0]\n",
    "ax.plot(df_train.index, df_train['return'] * 100, color='k', lw=0.6)\n",
    "is_bull = mpm_states == bull_state\n",
    "ymin, ymax = df_train['return'].min() * 100, df_train['return'].max() * 100\n",
    "ax.fill_between(df_train.index, ymin, ymax, where=is_bull, alpha=0.12, color='blue', label='Bull')\n",
    "ax.fill_between(df_train.index, ymin, ymax, where=~is_bull, alpha=0.12, color='red', label='Bear')\n",
    "ax.axhline(0, color='grey', lw=0.5)\n",
    "ax.set_ylabel('Monthly Return (%)')\n",
    "ax.set_title('Duration HMM — MPM Regime Reconstruction')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "# Add crisis annotations\n",
    "for start, end, label in crises:\n",
    "    try:\n",
    "        s = pd.Timestamp(start)\n",
    "        e = pd.Timestamp(end)\n",
    "        if s >= df_train.index[0] and s <= df_train.index[-1]:\n",
    "            ax.axvspan(s, e, alpha=0.08, color='grey')\n",
    "            ax.annotate(label, xy=(s + (e-s)/2, ymax*0.85),\n",
    "                       fontsize=7, ha='center', va='top', color='grey')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Panel 2: Bull probability\n",
    "ax = axes[1]\n",
    "ax.fill_between(df_train.index, 0, bull_prob_dhmm, alpha=0.4, color='steelblue')\n",
    "ax.axhline(0.5, color='r', ls='--', lw=0.8)\n",
    "ax.set_ylabel('P(Bull)')\n",
    "ax.set_title('Posterior Bull Probability — γ_t(bull)')\n",
    "ax.set_ylim(-0.05, 1.05)\n",
    "\n",
    "# Panel 3: Viterbi vs MPM comparison\n",
    "ax = axes[2]\n",
    "viterbi_bull = (viterbi_states == bull_state).astype(int)\n",
    "mpm_bull = (mpm_states == bull_state).astype(int)\n",
    "ax.step(df_train.index, mpm_bull, where='mid', color='steelblue', lw=1.2, label='MPM', alpha=0.8)\n",
    "ax.step(df_train.index, viterbi_bull * 0.95, where='mid', color='darkorange', lw=1.2, label='Viterbi', alpha=0.8)\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_yticklabels(['Bear', 'Bull'])\n",
    "ax.set_title('MPM vs Viterbi State Sequence')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Agreement\n",
    "agree = (mpm_bull == viterbi_bull).mean()\n",
    "print(f'MPM / Viterbi agreement: {agree:.1%}')\n",
    "print(f'Bull months (MPM): {mpm_bull.sum()} / {len(mpm_bull)} ({mpm_bull.mean():.1%})')\n",
    "print(f'Bear months (MPM): {(1-mpm_bull).sum()} / {len(mpm_bull)} ({(1-mpm_bull).mean():.1%})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Forecasting — Path Simulation vs Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Benchmark 1: AR(1)-GARCH(1,1) ---\n",
    "from arch import arch_model\n",
    "\n",
    "# Model 1: AR(1)-GARCH(1,1)\n",
    "y_pct_train = df_train['return'].values * 100  # in percent\n",
    "y_pct_test = df_test['return'].values * 100\n",
    "\n",
    "am1 = arch_model(y_pct_train, mean='AR', lags=1, vol='GARCH', p=1, q=1)\n",
    "res1 = am1.fit(disp='off')\n",
    "print('=== Model 1: AR(1)-GARCH(1,1) ===')\n",
    "print(res1.summary().tables[1])\n",
    "\n",
    "# Model 2: Rate-regression GARCH\n",
    "# r_t = c0 + c1*tbill_{t-1} + c2*spread_{t-1} + eps_t, eps_t ~ GARCH\n",
    "exog_train = df_train[['tbill', 'spread']].shift(1).dropna().values\n",
    "y_m2_train = y_pct_train[1:]  # align\n",
    "\n",
    "am2 = arch_model(y_m2_train, x=exog_train, mean='ARX', lags=0, vol='GARCH', p=1, q=1)\n",
    "res2 = am2.fit(disp='off')\n",
    "print('\\n=== Model 2: Rate-Regression GARCH ===')\n",
    "print(res2.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Duration HMM forecasts via path simulation (V=5000) ---\n",
    "H = len(df_test)\n",
    "Z_test = np.column_stack([\n",
    "    np.ones(H),\n",
    "    df_test['tbill'].values,\n",
    "    df_test['spread'].values\n",
    "])\n",
    "\n",
    "print(f'Simulating {5000} forecast paths for {H} months...')\n",
    "paths = dhmm.forecast_paths(Z_test, n_paths=5000)\n",
    "dhmm_forecast = paths.mean(axis=0)  # mean forecast\n",
    "dhmm_forecast_std = paths.std(axis=0)\n",
    "\n",
    "# --- Benchmark forecasts (rolling 1-step) ---\n",
    "# AR(1)-GARCH: use unconditional mean as multi-step forecast\n",
    "ar1_forecast = np.full(H, res1.params['Const'] / (1 - res1.params.get('y[1]', 0))) / 100\n",
    "\n",
    "# Rate-regression: use actual rates as if known (same assumption as in paper)\n",
    "exog_test = df_test[['tbill', 'spread']].values\n",
    "reg_forecast = np.full(H, res2.params['Const'])\n",
    "if 'x1' in res2.params:\n",
    "    reg_forecast += res2.params['x1'] * exog_test[:, 0]\n",
    "if 'x2' in res2.params:\n",
    "    reg_forecast += res2.params['x2'] * exog_test[:, 1]\n",
    "reg_forecast /= 100\n",
    "\n",
    "actual = df_test['return'].values\n",
    "\n",
    "# --- RMSE at various horizons ---\n",
    "def rolling_rmse(actual, forecast, horizon):\n",
    "    \"\"\"RMSE for rolling h-step ahead forecasts.\"\"\"\n",
    "    n = len(actual) - horizon + 1\n",
    "    if n <= 0:\n",
    "        return np.nan\n",
    "    errors = []\n",
    "    for i in range(n):\n",
    "        errors.append((actual[i:i+horizon].mean() - forecast[i:i+horizon].mean())**2)\n",
    "    return np.sqrt(np.mean(errors))\n",
    "\n",
    "horizons = [1, 3, 6, 12]\n",
    "rmse_table = []\n",
    "for h in horizons:\n",
    "    rmse_table.append({\n",
    "        'Horizon': f'+{h}m',\n",
    "        'AR(1)-GARCH': rolling_rmse(actual, ar1_forecast, h),\n",
    "        'Rate-Reg GARCH': rolling_rmse(actual, reg_forecast, h),\n",
    "        'Duration HMM': rolling_rmse(actual, dhmm_forecast, h),\n",
    "    })\n",
    "\n",
    "print('\\n=== Forecasting RMSE Comparison ===')\n",
    "display(pd.DataFrame(rmse_table).set_index('Horizon').round(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Forecast fan chart ---\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "ax.plot(df_test.index, actual * 100, 'k-', lw=1.2, label='Actual')\n",
    "ax.plot(df_test.index, dhmm_forecast * 100, 'b-', lw=1, label='DHMM Mean Forecast')\n",
    "ax.fill_between(df_test.index,\n",
    "                (dhmm_forecast - 2*dhmm_forecast_std) * 100,\n",
    "                (dhmm_forecast + 2*dhmm_forecast_std) * 100,\n",
    "                alpha=0.15, color='blue', label='DHMM ±2σ')\n",
    "ax.plot(df_test.index, ar1_forecast * 100, 'r--', lw=0.8, label='AR(1)-GARCH')\n",
    "ax.plot(df_test.index, reg_forecast * 100, 'g--', lw=0.8, label='Rate-Reg GARCH')\n",
    "ax.axhline(0, color='grey', lw=0.5)\n",
    "ax.set_ylabel('Monthly Return (%)')\n",
    "ax.set_title('Out-of-Sample Forecast Comparison')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. VaR Overlay — Regime-Conditional Value at Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Regime-conditional VaR ---\n",
    "# For each state j, VaR from the mixture distribution\n",
    "def mixture_var(c, mu, sigma2, alpha):\n",
    "    \"\"\"VaR at level alpha from mixture of normals via Monte Carlo.\"\"\"\n",
    "    n_sim = 100000\n",
    "    samples = np.zeros(n_sim)\n",
    "    for m in range(len(c)):\n",
    "        mask = np.random.rand(n_sim) < c[m] if m == 0 else (\n",
    "            np.random.rand(n_sim) < c[m] / (1 - sum(c[:m]))\n",
    "        )\n",
    "    # Simpler: just sample properly\n",
    "    comps = np.random.choice(len(c), size=n_sim, p=c)\n",
    "    for m in range(len(c)):\n",
    "        mask = comps == m\n",
    "        samples[mask] = np.random.normal(mu[m], np.sqrt(sigma2[m]), mask.sum())\n",
    "    return np.percentile(samples, alpha * 100)\n",
    "\n",
    "print('=== Regime-Conditional VaR ===')\n",
    "var_results = []\n",
    "for j in range(2):\n",
    "    var_95 = mixture_var(dhmm.c[j], dhmm.mu[j], dhmm.sigma2[j], 0.05)\n",
    "    var_99 = mixture_var(dhmm.c[j], dhmm.mu[j], dhmm.sigma2[j], 0.01)\n",
    "    var_results.append({\n",
    "        'State': state_labels[j],\n",
    "        'VaR 95%': f'{var_95*100:.2f}%',\n",
    "        'VaR 99%': f'{var_99*100:.2f}%',\n",
    "        'Mean Return': f'{state_means[j]*100:.2f}%',\n",
    "    })\n",
    "    \n",
    "display(pd.DataFrame(var_results).set_index('State'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Time-varying VaR using regime probabilities ---\n",
    "# VaR_t = gamma_t(bull) * VaR_bull + gamma_t(bear) * VaR_bear\n",
    "# (blended using posterior probabilities)\n",
    "\n",
    "n_sim = 50000\n",
    "\n",
    "def regime_blended_var(gamma_bull, dhmm, bull_state, bear_state, alpha, n_sim=50000):\n",
    "    \"\"\"Compute time-varying VaR blended by regime probability.\"\"\"\n",
    "    T = len(gamma_bull)\n",
    "    var_series = np.zeros(T)\n",
    "    \n",
    "    for t in range(T):\n",
    "        p_bull = gamma_bull[t]\n",
    "        samples = np.zeros(n_sim)\n",
    "        \n",
    "        # For each simulation draw, first pick regime, then mixture component\n",
    "        regime = np.random.binomial(1, p_bull, n_sim)  # 1=bull, 0=bear\n",
    "        \n",
    "        for j, state in [(1, bull_state), (0, bear_state)]:\n",
    "            mask = regime == j\n",
    "            n_j = mask.sum()\n",
    "            if n_j > 0:\n",
    "                comps = np.random.choice(dhmm.M, size=n_j, p=dhmm.c[state])\n",
    "                for m in range(dhmm.M):\n",
    "                    m_mask = comps == m\n",
    "                    n_m = m_mask.sum()\n",
    "                    if n_m > 0:\n",
    "                        samples[mask][m_mask] = np.random.normal(\n",
    "                            dhmm.mu[state, m], np.sqrt(dhmm.sigma2[state, m]), n_m\n",
    "                        )\n",
    "        \n",
    "        var_series[t] = np.percentile(samples, alpha * 100)\n",
    "    \n",
    "    return var_series\n",
    "\n",
    "var_95 = regime_blended_var(bull_prob_dhmm, dhmm, bull_state, bear_state, 0.05, n_sim=20000)\n",
    "var_99 = regime_blended_var(bull_prob_dhmm, dhmm, bull_state, bear_state, 0.01, n_sim=20000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.plot(df_train.index, df_train['return'] * 100, 'k-', lw=0.6, label='Actual Return')\n",
    "ax.plot(df_train.index, var_95 * 100, 'r-', lw=1, label='VaR 95%')\n",
    "ax.plot(df_train.index, var_99 * 100, 'darkred', lw=1, ls='--', label='VaR 99%')\n",
    "ax.fill_between(df_train.index, var_99 * 100, var_95 * 100, alpha=0.15, color='red')\n",
    "ax.set_ylabel('Monthly Return (%)')\n",
    "ax.set_title('Regime-Conditional Time-Varying VaR')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# VaR breach rates\n",
    "breach_95 = (df_train['return'].values < var_95).mean()\n",
    "breach_99 = (df_train['return'].values < var_99).mean()\n",
    "print(f'VaR 95% breach rate: {breach_95:.1%} (expected: 5.0%)')\n",
    "print(f'VaR 99% breach rate: {breach_99:.1%} (expected: 1.0%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Current Regime Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run model on full sample to get current regime ---\n",
    "Y_full = df['return'].values\n",
    "Z_full = np.column_stack([\n",
    "    np.ones(len(df)),\n",
    "    df['tbill'].values,\n",
    "    df['spread'].values\n",
    "])\n",
    "\n",
    "# Refit on full sample\n",
    "dhmm_full = DurationHMM(n_states=2, n_mix=3)\n",
    "dhmm_full.fit(Y_full, Z_full, max_iter=30, tol=1e-4, verbose=False)\n",
    "\n",
    "# Identify states\n",
    "full_means = [(dhmm_full.c[j] * dhmm_full.mu[j]).sum() for j in range(2)]\n",
    "full_bull = int(np.argmax(full_means))\n",
    "full_bear = 1 - full_bull\n",
    "\n",
    "gamma_full = dhmm_full.gamma_\n",
    "current_bull_prob = gamma_full[-1, full_bull]\n",
    "current_bear_prob = gamma_full[-1, full_bear]\n",
    "\n",
    "print('=' * 60)\n",
    "print('CURRENT REGIME ASSESSMENT')\n",
    "print('=' * 60)\n",
    "print(f'Date:              {df.index[-1].strftime(\"%Y-%m\")}')\n",
    "print(f'Latest return:     {df[\"return\"].iloc[-1]*100:.2f}%')\n",
    "print(f'T-Bill rate:       {df[\"tbill\"].iloc[-1]:.2f}%')\n",
    "print(f'10Y rate:          {df[\"gs10\"].iloc[-1]:.2f}%')\n",
    "print(f'Spread:            {df[\"spread\"].iloc[-1]:.2f}%')\n",
    "print(f'\\nRegime probabilities:')\n",
    "print(f'  P(Bull) = {current_bull_prob:.4f}')\n",
    "print(f'  P(Bear) = {current_bear_prob:.4f}')\n",
    "print(f'  => Current regime: {\"BULL\" if current_bull_prob > 0.5 else \"BEAR\"}')\n",
    "\n",
    "# Expected durations given current rates\n",
    "z_current = Z_full[-1]\n",
    "ed_bull = dhmm_full.expected_duration(z_current, full_bull)\n",
    "ed_bear = dhmm_full.expected_duration(z_current, full_bear)\n",
    "print(f'\\nExpected regime durations at current rates:')\n",
    "print(f'  Bull: {ed_bull:.1f} months')\n",
    "print(f'  Bear: {ed_bear:.1f} months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Full-sample regime timeline ---\n",
    "full_mpm = np.argmax(gamma_full, axis=1)\n",
    "full_bull_prob = gamma_full[:, full_bull]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 7), sharex=True)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(df.index, df['return'] * 100, 'k-', lw=0.6)\n",
    "is_bull_full = full_mpm == full_bull\n",
    "ymin, ymax = df['return'].min() * 100, df['return'].max() * 100\n",
    "ax.fill_between(df.index, ymin, ymax, where=is_bull_full, alpha=0.12, color='blue', label='Bull')\n",
    "ax.fill_between(df.index, ymin, ymax, where=~is_bull_full, alpha=0.12, color='red', label='Bear')\n",
    "\n",
    "for start, end, label in crises:\n",
    "    try:\n",
    "        s, e = pd.Timestamp(start), pd.Timestamp(end)\n",
    "        ax.axvspan(s, e, alpha=0.08, color='grey')\n",
    "        ax.annotate(label, xy=(s + (e-s)/2, ymax*0.85),\n",
    "                   fontsize=7, ha='center', va='top', color='grey')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "ax.axhline(0, color='grey', lw=0.5)\n",
    "ax.set_ylabel('Monthly Return (%)')\n",
    "ax.set_title('Duration HMM — Full Sample Regime Reconstruction')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.fill_between(df.index, 0, full_bull_prob, alpha=0.5, color='steelblue')\n",
    "ax.axhline(0.5, color='r', ls='--', lw=0.8)\n",
    "ax.set_ylabel('P(Bull)')\n",
    "ax.set_title('Bull Market Posterior Probability (Full Sample)')\n",
    "ax.set_ylim(-0.05, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Summary dashboard ---\n",
    "print('=' * 70)\n",
    "print('DURATION HMM — MODEL SUMMARY')\n",
    "print('=' * 70)\n",
    "print(f'Sample:          {df.index[0].strftime(\"%Y-%m\")} to {df.index[-1].strftime(\"%Y-%m\")} ({len(df)} months)')\n",
    "print(f'States:          {dhmm.N} (bull/bear)')\n",
    "print(f'Mixture comps:   {dhmm.M} per state')\n",
    "print(f'Duration covars: intercept, T-bill, spread')\n",
    "print(f'Max duration:    {dhmm.max_dur} months')\n",
    "print(f'Log-likelihood:  {dhmm.log_lik_:.4f}')\n",
    "print(f'\\n--- Current Assessment ({df.index[-1].strftime(\"%Y-%m\")}) ---')\n",
    "print(f'Regime:          {\"BULL\" if current_bull_prob > 0.5 else \"BEAR\"} (P={max(current_bull_prob, current_bear_prob):.2%})')\n",
    "print(f'Expected bull duration: {ed_bull:.0f} months at current rates')\n",
    "print(f'Expected bear duration: {ed_bear:.0f} months at current rates')\n",
    "print(f'\\n--- Key Findings ---')\n",
    "print(f'Bull: higher T-bill => shorter duration (kappa_2 = {dhmm_full.kappa[full_bull, 1]:.4f})')\n",
    "print(f'Bull: higher spread => longer duration  (kappa_3 = {dhmm_full.kappa[full_bull, 2]:.4f})')\n",
    "print(f'Bear: higher T-bill => longer duration  (kappa_2 = {dhmm_full.kappa[full_bear, 1]:.4f})')\n",
    "print(f'Bear: higher spread => shorter duration (kappa_3 = {dhmm_full.kappa[full_bear, 2]:.4f})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}